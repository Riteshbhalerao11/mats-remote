{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f79833-2e04-492a-b307-9896f943cd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Compatibility for older code referencing np.bool\n",
    "if not hasattr(np, \"bool\"):\n",
    "    np.bool = bool \n",
    "\n",
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from nnsight import LanguageModel\n",
    "from crosscoder_learning.dictionary_learning.cache import ActivationCache\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfab80a0-cf46-41d7-9a8d-045729639ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ActivationCollectionArgs:\n",
    "    # Model + dataset\n",
    "    model: str = \"/pscratch/sd/r/ritesh11/temp/Qwen3-30B-A3B\"\n",
    "    dataset: str = \"prompts\"\n",
    "    dataset_split: str = \"eval\"\n",
    "    text_column: str = \"text\"\n",
    "\n",
    "    # Activation collection\n",
    "    activation_store_dir: str = \"model_activations\"\n",
    "    layers: List[int] = field(default_factory=lambda: [22])\n",
    "    batch_size: int = 1  # There appears to be a bug with batch size > 1\n",
    "    context_len: int = 3008\n",
    "    overwrite: bool = False\n",
    "    store_tokens: bool = True\n",
    "    disable_multiprocessing: bool = False\n",
    "\n",
    "    # Limits\n",
    "    num_samples: int = 10 ** 6\n",
    "    max_tokens: int = 10 ** 8\n",
    "\n",
    "    # Data type\n",
    "    dtype: str = \"auto\"  # choices: \"bfloat16\", \"float16\", \"float32\"\n",
    "    random_seed: int = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c1c547-d49c-4b2a-b308-ae27caff65da",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ActivationCollectionArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8423b1a6-b1ab-48f6-96f7-bdaa80dff4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dtype_str == \"bfloat16\":\n",
    "    return torch.bfloat16\n",
    "if dtype_str == \"float16\":\n",
    "    return torch.float16\n",
    "if dtype_str == \"float32\":\n",
    "    return torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a809e8d-5303-4363-947b-4fe401acadd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Convert dtype string to torch dtype\n",
    "torch_dtype = dtype_from_string(args.dtype)\n",
    "\n",
    "# Load model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    args.model,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch_dtype,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c430fe-5173-4223-a591-92e68a3b58d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap with nnsight\n",
    "nnmodel = LanguageModel(model, tokenizer=tokenizer)\n",
    "\n",
    "# Submodules to trace\n",
    "submodules = [nnmodel.model.layers[layer_idx] for layer_idx in args.layers]\n",
    "submodule_names = [f\"layer_{layer_idx}\" for layer_idx in args.layers]\n",
    "d_model = nnmodel._model.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaba0b5-baf7-4ed4-af49-69a99d21906a",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_dir = Path(args.activation_store_dir)\n",
    "store_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "out_dir = store_dir / args.dataset_split\n",
    "out_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce103f4-c008-45f8-8a51-7dae383d7717",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(args.dataset)\n",
    "dataset = dataset[args.dataset_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378579db-52fe-426a-aecc-730810bba57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_messages(example):\n",
    "    formatted = tokenizer.apply_chat_template(\n",
    "        example[\"messages\"],\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=False,\n",
    "    )\n",
    "    return {\"text\": formatted}\n",
    "\n",
    "dataset = dataset.map(format_messages, remove_columns=dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2777b80-6bc3-4745-b6ba-311a651754a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ActivationCache.collect(\n",
    "    dataset[args.text_column],\n",
    "    submodules,\n",
    "    submodule_names,\n",
    "    nnmodel,\n",
    "    out_dir,\n",
    "    shuffle_shards=False,\n",
    "    io=\"out\",\n",
    "    shard_size=10 ** 6,\n",
    "    batch_size=args.batch_size,\n",
    "    context_len=args.context_len,\n",
    "    d_model=d_model,\n",
    "    last_submodule=submodules[-1],\n",
    "    max_total_tokens=args.max_tokens,\n",
    "    store_tokens=args.store_tokens,\n",
    "    multiprocessing=not args.disable_multiprocessing,\n",
    "    ignore_first_n_tokens_per_sample=0,\n",
    "    overwrite=args.overwrite,\n",
    "    token_level_replacement=None,\n",
    "    add_special_tokens=False\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
